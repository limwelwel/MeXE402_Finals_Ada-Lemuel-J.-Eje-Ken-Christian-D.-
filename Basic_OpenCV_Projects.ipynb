{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpFzPRAjg4uf"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/misbah4064/opencvTutorial.git\n",
    "%cd opencvTutorial/\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsrgFohWje1Q"
   },
   "source": [
    "# **14 Basic OpenCV Projects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XWeg4TQgmFS"
   },
   "source": [
    "## **1: Converting Images to Grayscale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "kHhk1fzMh3KO",
    "outputId": "2b48be7f-e2f8-4020-c80d-cfab43fdfd44"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "#colorful image - 3 channels\n",
    "image = cv2.imread(\"images/color.jpg\")\n",
    "print(image.shape)\n",
    "\n",
    "#grayscale image\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "print(gray.shape)\n",
    "cv2_imshow(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plz006OpgzqQ"
   },
   "source": [
    "## **2. Visualizing Edge Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "gzmgH6QPh4Bo",
    "outputId": "4ba5cba0-ee18-406e-e866-8b8c6e03206c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"images/color.jpg\")\n",
    "# cv2_imshow(image)\n",
    "\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "canny_image = cv2.Canny(gray,150, 200)\n",
    "# cv2_imshow(canny_image)\n",
    "\n",
    "# Erosion and Dilation\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "#Dilation\n",
    "dilate_image = cv2.dilate(canny_image, kernel, iterations=1)\n",
    "# cv2_imshow(dilate_image)\n",
    "#Erosion\n",
    "# kernel = np.ones((1,1), np.uint8)\n",
    "erode_image = cv2.erode(dilate_image,kernel, iterations=1)\n",
    "# cv2_imshow(erode_image)\n",
    "\n",
    "display = np.hstack((canny_image,dilate_image,erode_image))\n",
    "cv2_imshow(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7J2otaqOdgT"
   },
   "source": [
    "## **3. Demonstrating Morphological Erosion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aBW5jTj0OcC0",
    "outputId": "9a1833f3-d7cf-4e6e-cfdb-a6f745ffd8fd"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Load an image\n",
    "image_path = 'images/color.jpg'  # Replace with your image path\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "\n",
    "# Check if the image loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Unable to load the image. Check the image path.\")\n",
    "else:\n",
    "    # Display the original image\n",
    "    print(\"Original Image:\")\n",
    "    cv2_imshow(image)\n",
    "\n",
    "    # Define different kernel sizes for erosion\n",
    "    kernel_sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "\n",
    "    # Apply erosion for each kernel size and display the result\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # Create the kernel\n",
    "        kernel = np.ones(kernel_size, np.uint8)\n",
    "\n",
    "        # Perform erosion\n",
    "        eroded_image = cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "        # Display the eroded image\n",
    "        print(f\"Eroded Image with Kernel Size {kernel_size}:\")\n",
    "        cv2_imshow(eroded_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUBYx2MYO5-A"
   },
   "source": [
    "## **4. Demonstrating Morphological Dilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vroSeO3tO6Sf"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Create a binary image for demonstration (white shapes on black background)\n",
    "image = np.zeros((300, 300), dtype=np.uint8)\n",
    "cv2.rectangle(image, (50, 50), (100, 100), 255, -1)  # Filled rectangle\n",
    "cv2.circle(image, (200, 200), 30, 255, -1)           # Filled circle\n",
    "cv2.rectangle(image, (120, 120), (140, 140), 255, -1) # Small square\n",
    "\n",
    "# Introduce a small gap between shapes\n",
    "cv2.line(image, (100, 75), (120, 75), 0, 3)          # Black line creating a gap\n",
    "\n",
    "# Display the original binary image\n",
    "print(\"Original Binary Image:\")\n",
    "cv2_imshow(image)\n",
    "\n",
    "# Define the kernel for dilation\n",
    "kernel = np.ones((5, 5), np.uint8)  # 5x5 square kernel\n",
    "\n",
    "# Apply the dilation operation\n",
    "dilated_image = cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "# Display the dilated image\n",
    "print(\"Image After Morphological Dilation:\")\n",
    "cv2_imshow(dilated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSyj7NF9h487"
   },
   "source": [
    "## **5. Reducing Noise in Photos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "JR5eorBCh_QV",
    "outputId": "63a53f7c-51f3-422e-b90b-2daca0ebdfa7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"images/lion.jpg\")\n",
    "# cv2_imshow(image)\n",
    "dst = cv2.fastNlMeansDenoisingColored(image, None, 50, 20, 7, 15)\n",
    "\n",
    "display = np.hstack((image, dst))\n",
    "cv2_imshow(display)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ4PXXVXiABu"
   },
   "source": [
    "## **6. Drawing Geometric Shapes on Images**\n",
    "## **7. Adding Text to Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "8VE9jXUliPYM",
    "outputId": "703fb661-7f2f-4c47-ef61-bb7520e00a1f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "#uint8: 0 to 255\n",
    "\n",
    "# Drawing Function\n",
    "# Draw a Circle\n",
    "cv2.circle(img, (100,100), 50, (0,255,0),5)\n",
    "# Draw a Rectangle\n",
    "cv2.rectangle(img,(200,200),(400,500),(0,0,255),5)\n",
    "#Draw a Line\n",
    "cv2.line(img, (160,160),(359,29),(255,0,0),3)\n",
    "#Write a Text\n",
    "cv2.putText(img,\"OpenCV\",(160,160),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,255),2)\n",
    "# Displaying the Image\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBn_p2MFkKzD"
   },
   "source": [
    "## **8. Isolating Objects by Color**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "DqQKb20akUfK",
    "outputId": "0014b71d-facd-4636-caf6-a3a3ed638c37"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "#BGR Image . It is represented in Blue, Green and Red Channels...\n",
    "image = cv2.imread(\"images/shapes.png\")\n",
    "hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Blue Color Triangle\n",
    "# lower_hue = np.array([65,0,0])\n",
    "# upper_hue = np.array([110, 255,255])\n",
    "\n",
    "# Red Color\n",
    "# lower_hue = np.array([0,0,0])\n",
    "# upper_hue = np.array([20,255, 255])\n",
    "\n",
    "# Green Color\n",
    "# lower_hue = np.array([46,0,0])\n",
    "# upper_hue = np.array([91,255,255])\n",
    "\n",
    "# Yellow Color\n",
    "lower_hue = np.array([21,0,0])\n",
    "upper_hue = np.array([45,255,255])\n",
    "\n",
    "mask = cv2.inRange(hsv,lower_hue,upper_hue)\n",
    "# cv2_imshow(mask)\n",
    "result = cv2.bitwise_and(image, image, mask = mask)\n",
    "cv2_imshow(result)\n",
    "# cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clI52ToRkVWt"
   },
   "source": [
    "## **9. Detecting Faces in Group Photos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5u7bJNRJkZAV",
    "outputId": "1c76c0eb-9662-44ae-a99e-adbd4a831485"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"files/haarcascade_frontalface_default.xml\")\n",
    "# img = cv2.imread(\"images/person.jpg\")\n",
    "img = cv2.imread(\"images/group.jpg\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "# print(faces)\n",
    "for (x,y,w,h) in faces:\n",
    "  cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "\n",
    "cv2_imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzmPUrB7lQS8"
   },
   "source": [
    "## **10. Outlining Shapes with Contours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "K9lMGFuPFH1e",
    "outputId": "cd9fc1bc-fd40-409b-a603-01814bcc75ee"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "img = cv2.imread(\"images/shapes.png\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray,50,255,1)\n",
    "contours,h = cv2.findContours(thresh,1,2)\n",
    "# cv2_imshow(thresh)\n",
    "for cnt in contours:\n",
    "  approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
    "  n = len(approx)\n",
    "  if n==6:\n",
    "    # this is a hexagon\n",
    "    print(\"We have a hexagon here\")\n",
    "    cv2.drawContours(img,[cnt],0,255,10)\n",
    "  elif n==3:\n",
    "    # this is a triangle\n",
    "    print(\"We found a triangle\")\n",
    "    cv2.drawContours(img,[cnt],0,(0,255,0),3)\n",
    "  elif n>9:\n",
    "    # this is a circle\n",
    "    print(\"We found a circle\")\n",
    "    cv2.drawContours(img,[cnt],0,(0,255,255),3)\n",
    "  elif n==4:\n",
    "    # this is a Square\n",
    "    print(\"We found a square\")\n",
    "    cv2.drawContours(img,[cnt],0,(255,255,0),3)\n",
    "cv2_imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iyhp4BtUzkkc"
   },
   "source": [
    "## **11. Tracking a Ball in a Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fT0IYyHkzwHz"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "ball = []\n",
    "cap = cv2.VideoCapture(\"videos/video.mp4\")\n",
    "out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'),10,(1920,1080))\n",
    "while cap.isOpened():\n",
    "  ret, frame = cap.read()\n",
    "  if ret is False:\n",
    "    break\n",
    "  hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "  lower_hue = np.array([21,0,0])\n",
    "  upper_hue = np.array([45,255,255])\n",
    "  mask = cv2.inRange(hsv,lower_hue, upper_hue)\n",
    "\n",
    "  (contours,_)=cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  center = None\n",
    "\n",
    "  if len(contours)>0:\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    ((x,y),radius) = cv2.minEnclosingCircle(c)\n",
    "    M = cv2.moments(c)\n",
    "    try:\n",
    "      center = (int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"]))\n",
    "      cv2.circle(frame, center,10, (255,0,0),-1)\n",
    "      ball.append(center)\n",
    "    except:\n",
    "      pass\n",
    "    if len(ball)>2:\n",
    "      for i in range(1,len(ball)):\n",
    "        cv2.line(frame, ball[i-1], ball[i],(0,0,255),5)\n",
    "  out.write(frame)\n",
    "out.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsmHcNs9lM0E"
   },
   "source": [
    "## **12. Highlighting Detected Faces**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLHiOj_ulkJf"
   },
   "source": [
    "Clone Repositories and download dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxtCqloulRyv",
    "outputId": "bf8e03df-bfca-4c1d-82da-3e7833125bfb"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/misbah4064/face_recognition.git\n",
    "!pip install face_recognition\n",
    "%cd face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svvXPUHOljFf"
   },
   "source": [
    "Create Encoding Profiles using known face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSsnaOqItFor"
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "# Creating the encoding profiles\n",
    "face_1 = face_recognition.load_image_file(\"elon.jpg\")\n",
    "face_1_encoding = face_recognition.face_encodings(face_1)[0]\n",
    "\n",
    "face_2 = face_recognition.load_image_file(\"Donald Trump.jpg\")\n",
    "face_2_encoding = face_recognition.face_encodings(face_2)[0]\n",
    "\n",
    "face_3 = face_recognition.load_image_file(\"jeffbezos.jpg\")\n",
    "face_3_encoding = face_recognition.face_encodings(face_3)[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "                        face_1_encoding,\n",
    "                        face_2_encoding,\n",
    "                        face_3_encoding\n",
    "]\n",
    "\n",
    "known_face_names = [\n",
    "                    \"Elon Musk\",\n",
    "                    \"Donald Trump\",\n",
    "                    \"Jeff Bezos\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwKo0_-Vl1Uv"
   },
   "source": [
    "Run Face Recognition on unknown faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "MrRTVrE7tGNy",
    "outputId": "c2b9602e-0463-4d45-fbbe-1d4c1bb97462"
   },
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"unknown_do.jpg\"\n",
    "unknown_image = face_recognition.load_image_file(file_name)\n",
    "unknown_image_to_draw = cv2.imread(file_name)\n",
    "\n",
    "face_locations = face_recognition.face_locations(unknown_image)\n",
    "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "for (top,right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "  matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "  name = \"Unknown\"\n",
    "\n",
    "  face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "  best_match_index = np.argmin(face_distances)\n",
    "  if matches[best_match_index]:\n",
    "    name = known_face_names[best_match_index]\n",
    "  cv2.rectangle(unknown_image_to_draw, (left, top), (right, bottom),(0,255,0),3)\n",
    "  cv2.putText(unknown_image_to_draw,name, (left, top-20), cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2, cv2.LINE_AA)\n",
    "\n",
    "cv2_imshow(unknown_image_to_draw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNnkfZU-Paaq"
   },
   "source": [
    "## **13. Extracting Contours for Shape Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "6YlSUPzuPapr",
    "outputId": "e27a384b-fe69-4660-ba51-c8d8ff87919f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Load the hand-drawn image\n",
    "image_path = 'images/color.jpg'  # Update with your image path\n",
    "image = cv2.imread(image_path)\n",
    "original_image = image.copy()\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Perform edge detection\n",
    "edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Analyze and outline shapes\n",
    "for contour in contours:\n",
    "    # Approximate the shape\n",
    "    epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "    # Draw contours\n",
    "    cv2.drawContours(original_image, [approx], -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Get the center of the contour\n",
    "    M = cv2.moments(contour)\n",
    "    if M['m00'] != 0:\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "    else:\n",
    "        cx, cy = 0, 0\n",
    "\n",
    "    # Identify the shape\n",
    "    if len(approx) == 3:\n",
    "        shape_name = \"Triangle\"\n",
    "    elif len(approx) == 4:\n",
    "        # Check for square or rectangle\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        aspect_ratio = float(w) / h\n",
    "        shape_name = \"Square\" if 0.95 <= aspect_ratio <= 1.05 else \"Rectangle\"\n",
    "    elif len(approx) > 10:\n",
    "        shape_name = \"Circle\"\n",
    "    else:\n",
    "        shape_name = \"Polygon\"\n",
    "\n",
    "    # Write the shape name on the image\n",
    "    cv2.putText(original_image, shape_name, (cx - 50, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the processed image\n",
    "cv2_imshow(original_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o4aKQ0NPbA2"
   },
   "source": [
    "## **14. Applying Image Blurring Techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zyl26ODYPbLv",
    "outputId": "a85c7e05-470b-456b-c052-e0e798743fb0"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Load the image\n",
    "image_path = 'images/color.jpg'  # Replace with your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Display the original image\n",
    "print(\"Original Image:\")\n",
    "cv2_imshow(image)\n",
    "\n",
    "# Apply Gaussian Blur\n",
    "# (ksize must be odd and positive, e.g., (5,5))\n",
    "gaussian_blur = cv2.GaussianBlur(image, (15, 15), 0)\n",
    "print(\"Gaussian Blurred Image:\")\n",
    "cv2_imshow(gaussian_blur)\n",
    "\n",
    "# Apply Median Blur\n",
    "# (ksize must be odd and greater than 1, e.g., 5)\n",
    "median_blur = cv2.medianBlur(image, 15)\n",
    "print(\"Median Blurred Image:\")\n",
    "cv2_imshow(median_blur)\n",
    "\n",
    "# Save the blurred images\n",
    "cv2.imwrite('/mnt/data/gaussian_blur.jpg', gaussian_blur)\n",
    "cv2.imwrite('/mnt/data/median_blur.jpg', median_blur)\n",
    "\n",
    "print(\"Blurred images saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
